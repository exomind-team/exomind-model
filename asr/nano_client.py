"""
Fun-ASR-Nano-2512 Client
========================

Fun-ASR-Nano-2512 å®æ—¶è¯­éŸ³è¯†åˆ«å¼•æ“å®ç°ã€‚

ä½¿ç”¨é˜¿é‡Œé€šä¹‰ Fun-ASR-Nano-2512 æ¨¡å‹ï¼Œæ”¯æŒï¼š
- ä½å»¶è¿Ÿå®æ—¶è½¬å†™ï¼ˆ<600msï¼‰
- 31 ç§è¯­è¨€è¯†åˆ«
- 7 ç§ä¸­æ–‡æ–¹è¨€ + 26 ç§å£éŸ³
- æµå¼éŸ³é¢‘å¤„ç†
"""

import time
from typing import AsyncGenerator, Dict, Any, Optional

from .base import ASRClient
from .result import StreamingResult, StreamingState


class FunASRNanoClient(ASRClient):
    """
    Fun-ASR-Nano-2512 å®æ—¶ ASR å¼•æ“å®¢æˆ·ç«¯

    ç‰¹ç‚¹ï¼š
    - åŸç”Ÿæµå¼æ”¯æŒï¼Œå»¶è¿Ÿ < 600ms
    - 31 ç§è¯­è¨€ï¼Œ7 ç§ä¸­æ–‡æ–¹è¨€
    - æ¨ç†é€Ÿåº¦ â‰¥1x å®æ—¶ç‡
    - æ˜¾å­˜å ç”¨ < 4GB
    """

    # æ”¯æŒçš„æ¨¡å‹
    SUPPORTED_MODELS = {
        'nano-2512': 'Fun-ASR-Nano-2512 (å¤šè¯­è¨€ï¼Œ31ç§è¯­è¨€)',
        'nano-mlt': 'Fun-ASR-MLT-Nano-2512 (å¤šè¯­è¨€å¢å¼ºç‰ˆ)',
    }

    # æ¨¡å‹ä»“åº“æ˜ å°„
    MODEL_REPO_MAP = {
        'nano-2512': 'FunAudioLLM/Fun-ASR-Nano-2512',
        'nano-mlt': 'FunAudioLLM/Fun-ASR-MLT-Nano-2512',
    }

    def __init__(self, model: str = 'nano-2512', device: str = 'cpu'):
        """
        åˆå§‹åŒ– Fun-ASR-Nano-2512 å®¢æˆ·ç«¯

        Args:
            model: æ¨¡å‹åç§° (nano-2512 / nano-mlt)
            device: è®¡ç®—è®¾å¤‡ (cuda / cpu)
        """
        self._model_name = model
        self._device = device
        self._model_instance = None
        self._model_kwargs = None
        self._chunk_start_time = 0.0
        self._load_model()

    def _load_model(self):
        """åŠ è½½ Fun-ASR-Nano-2512 æ¨¡å‹"""
        try:
            from funasr import AutoModel

            repo_id = self.MODEL_REPO_MAP.get(self._model_name, self._model_name)
            print(f"ğŸ”„ åŠ è½½ Fun-ASR-Nano-2512 æ¨¡å‹: {repo_id}")
            print(f"   è®¾å¤‡: {self._device}")

            # Fun-ASR-Nano-2512 éœ€è¦ä½¿ç”¨ trust_remote_code å’Œ remote_code å‚æ•°
            # remote_code æŒ‡å‘ä»“åº“ä¸­çš„ model.py
            import os
            model_dir = os.path.dirname(os.path.abspath(__file__))
            remote_code = os.path.join(model_dir, "model.py")

            self._model_instance = AutoModel(
                model=repo_id,
                trust_remote_code=True,
                remote_code=remote_code,
                device=self._device,
                disable_update=True
            )

            # æ¨¡å‹å‚æ•°å­—å…¸ï¼ˆç”¨äº inference è°ƒç”¨ï¼‰
            self._model_kwargs = {}

            print(f"âœ… Fun-ASR-Nano-2512 æ¨¡å‹åŠ è½½æˆåŠŸ")

        except ImportError as e:
            raise RuntimeError(
                f"Fun-ASR-Nano-2512 ä¾èµ–æœªå®‰è£…: {e}\n"
                "è¯·ç¡®ä¿å·²å®‰è£…: pip install funasr modelscope\n"
                "æˆ–å‚è€ƒ: https://github.com/FunAudioLLM/Fun-ASR"
            )
        except Exception as e:
            raise RuntimeError(f"Fun-ASR-Nano-2512 æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    @property
    def name(self) -> str:
        return f"Fun-ASR-Nano-2512 ({self._model_name})"

    @property
    def is_available(self) -> bool:
        return self._model_instance is not None

    def transcribe(self, audio_path: str) -> str:
        """
        è½¬å†™éŸ³é¢‘æ–‡ä»¶ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            è¯†åˆ«åçš„æ–‡æœ¬
        """
        if not self._model_instance:
            raise RuntimeError("Fun-ASR-Nano-2512 æ¨¡å‹æœªåŠ è½½")

        try:
            # ç¦»çº¿è½¬å†™
            results = self._model_instance.inference(
                [audio_path],
                **self._model_kwargs
            )

            # æå–æ–‡æœ¬
            if results and len(results) > 0:
                result = results[0]
                if isinstance(result, list) and len(result) > 0:
                    # æ ¼å¼: [[{"text": "è¯†åˆ«æ–‡æœ¬"}]]
                    return result[0].get('text', '')
                elif isinstance(result, dict):
                    return result.get('text', '')

            return ""

        except Exception as e:
            raise RuntimeError(f"Fun-ASR-Nano-2512 è½¬å†™å¤±è´¥: {e}")

    def transcribe_chunk(self, chunk: bytes) -> StreamingResult:
        """
        å•æ¬¡æµå¼è½¬å†™ï¼ˆé«˜æ•ˆæ¨¡å¼ï¼‰

        Args:
            chunk: éŸ³é¢‘ç‰‡æ®µï¼ˆbytesï¼‰

        Returns:
            StreamingResult: æµå¼è¯†åˆ«ç»“æœ
        """
        if not self._model_instance:
            raise RuntimeError("Fun-ASR-Nano-2512 æ¨¡å‹æœªåŠ è½½")

        start_time = time.time()

        try:
            # æµå¼æ¨ç† - è¿”å›ç¬¬ä¸€ä¸ªç»“æœ
            for result in self._model_instance.inference_stream([chunk]):
                # æå–æ–‡æœ¬
                text = ""
                if result and len(result) > 0:
                    r = result[0]
                    if isinstance(r, list) and len(r) > 0:
                        text = r[0].get('text', '')
                    elif isinstance(r, dict):
                        text = r.get('text', '')

                chunk_duration = time.time() - start_time

                return StreamingResult(
                    text=text,
                    state=StreamingState.INTERMEDIATE,
                    is_final=True,
                    confidence=1.0,
                    start_time=self._chunk_start_time,
                    end_time=self._chunk_start_time + chunk_duration,
                    chunk_duration=chunk_duration,
                )

            # æ— ç»“æœè¿”å›ç©º
            return StreamingResult(text="")

        except Exception as e:
            raise RuntimeError(f"Fun-ASR-Nano-2512 æµå¼è½¬å†™å¤±è´¥: {e}")

    async def transcribe_streaming(
        self,
        audio_chunks: AsyncGenerator[bytes, None],
    ) -> AsyncGenerator[StreamingResult, None]:
        """æµå¼è½¬å†™ï¼ˆå®æ—¶æ¨¡å¼ï¼‰

        Args:
            audio_chunks: éŸ³é¢‘æ•°æ®å¼‚æ­¥ç”Ÿæˆå™¨

        Yields:
            StreamingResult: æµå¼è¯†åˆ«ç»“æœ
        """
        self._chunk_start_time = 0.0
        chunk_index = 0

        async for chunk in audio_chunks:
            result = self.transcribe_chunk(chunk)

            # æ›´æ–°å¼€å§‹æ—¶é—´ï¼ˆç´¯è®¡ï¼‰
            if chunk_index > 0:
                # å‡è®¾æ¯ä¸ªå—çº¦ 100msï¼Œç´¯ç§¯è®¡ç®—æ—¶é—´
                result.start_time = chunk_index * 0.1
                result.end_time = result.start_time + result.chunk_duration

            yield result
            chunk_index += 1

    def start_streaming_session(self):
        """å¼€å§‹æµå¼ä¼šè¯ï¼ˆé‡ç½®æ—¶é—´æˆ³ï¼‰"""
        self._chunk_start_time = 0.0

    def end_streaming_session(self) -> StreamingResult:
        """ç»“æŸæµå¼ä¼šè¯"""
        return StreamingResult(
            text="",
            state=StreamingState.COMPLETED,
            is_final=True,
        )

    def transcribe_audio_data(self, audio_data) -> str:
        """
        è½¬å†™éŸ³é¢‘æ•°æ®ï¼ˆä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ï¼‰

        Args:
            audio_data: numpy éŸ³é¢‘æ•°ç»„

        Returns:
            è¯†åˆ«åçš„æ–‡æœ¬
        """
        import tempfile
        import wave
        import os

        # ä¿å­˜ä¸ºä¸´æ—¶ WAV æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
            temp_path = f.name

        # å†™å…¥ WAV
        try:
            with wave.open(temp_path, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(16000)
                wf.writeframes(audio_data.astype('int16').tobytes())

            return self.transcribe(temp_path)
        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def batch_transcribe(self, audio_paths: list) -> list:
        """
        æ‰¹é‡è½¬å†™éŸ³é¢‘æ–‡ä»¶

        Args:
            audio_paths: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            è¯†åˆ«æ–‡æœ¬åˆ—è¡¨
        """
        if not self._model_instance:
            raise RuntimeError("Fun-ASR-Nano-2512 æ¨¡å‹æœªåŠ è½½")

        try:
            results = self._model_instance.inference(
                audio_paths,
                **self._model_kwargs
            )

            texts = []
            for result in results:
                if isinstance(result, list) and len(result) > 0:
                    texts.append(result[0].get('text', ''))
                elif isinstance(result, dict):
                    texts.append(result.get('text', ''))
                else:
                    texts.append('')

            return texts

        except Exception as e:
            raise RuntimeError(f"Fun-ASR-Nano-2512 æ‰¹é‡è½¬å†™å¤±è´¥: {e}")
